{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.301 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.301 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from NLP import comment_analysis as ca\n",
    "from gensim import corpora, models\n",
    "\n",
    "\n",
    "doc = ca.prepare_news_to_corpora(\"news540\")\n",
    "doc_tokens = doc[\"doc_bodies\"]\n",
    "dictionary = corpora.Dictionary(doc_tokens) \n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in doc_tokens]\n",
    "tags = doc[\"tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.导入需要的模型库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.异常数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 ['-1' '-2' '0' '1' '2']\n"
     ]
    }
   ],
   "source": [
    "tags_tmp = []\n",
    "for tag in tags:\n",
    "    if tag == \"\":\n",
    "        tags_tmp.append(\"0\")\n",
    "    else:\n",
    "        tags_tmp.append(tag)\n",
    "\n",
    "tags = tags_tmp\n",
    "\n",
    "n_tags = len(np.unique(tags))\n",
    "labels = tags\n",
    "print n_tags,np.unique(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.lda模型，转换成sparse matrix，并用scale标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load lda模型\n",
    "lda = models.LdaMulticore.load(\"result/lda_model_caicai_tfidf_50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda = models.LdaMulticore(tfidf_corpus, num_topics=150, passes=50, iterations=50, id2word=dictionary)\n",
    "#lda.save(\"result/lda_model_jinjin_tfidf_150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda = models.LdaMulticore(corpus, num_topics=150, passes=50, iterations=50, id2word=dictionary)\n",
    "#lda.save(\"result/lda_model_jinjin_150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#aa = lda[corpus]\n",
    "aa = lda[tfidf_corpus]\n",
    "s_l = []\n",
    "for ll in aa:\n",
    "    s_l.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 34 40 ..., 34 40 48]\n",
      "[  0   0   0 ..., 539 539 539]\n"
     ]
    }
   ],
   "source": [
    "s_m = ca.list2SP(s_l)\n",
    "print s_m.col\n",
    "print s_m.row\n",
    "\n",
    "data = scale(s_m, with_mean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.聚类，尝试k-means++/random/pca降维,比较效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置参数，聚类个数及初始点个数\n",
    "n_clusters = 10\n",
    "n_init = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=10, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k-means++\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=n_init)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random\n",
    "kmeans = KMeans(init='random', n_clusters=n_clusters, n_init=n_init)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=10, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pca降维+\"k-means++\"\n",
    "reduced_data = PCA(n_components=5).fit_transform(data.toarray())\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=n_init)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "#pca降维\n",
    "#pca = PCA(n_components=5).fit(data.toarray())\n",
    "#kmeans_pca = KMeans(init=pca.components_, n_clusters=10, n_init=10)\n",
    "#kmeans_pca.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.计算每个类的样本数以及到中心点最近的样本点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 129\n",
      "1 131\n",
      "2 73\n",
      "3 35\n",
      "4 29\n",
      "5 31\n",
      "6 30\n",
      "7 37\n",
      "8 22\n",
      "9 23\n"
     ]
    }
   ],
   "source": [
    "#clus_pred = kmeans.labels_\n",
    "clus_pred = kmeans.predict(reduced_data)\n",
    "\n",
    "#print set(clus_pred)\n",
    "#print len(clus_pred)\n",
    "\n",
    "\n",
    "k_s = {}\n",
    "for i, p in enumerate(clus_pred):\n",
    "    if p in k_s:\n",
    "        k_s[p].append(i)\n",
    "    else:\n",
    "        k_s[p] = []\n",
    "        k_s[p].append(i)\n",
    "        \n",
    "for k in k_s:\n",
    "    print k,len(k_s[k])\n",
    " \n",
    "#print k_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.291108780961 289\n",
      "1 0.442603693973 348\n",
      "2 0.547483494503 359\n",
      "3 0.37895093721 297\n",
      "4 0.453194940295 409\n",
      "5 0.330853212443 519\n",
      "6 0.727555609374 304\n",
      "7 0.227809048447 232\n",
      "8 0.306354817742 472\n",
      "9 0.30385854557 464\n",
      "0.291108780961\n"
     ]
    }
   ],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "#print centroids\n",
    "\n",
    "#print reduced_data[0:5],len(reduced_data)\n",
    "\n",
    "def dist(x,y):\n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "for i , cent in enumerate(centroids):\n",
    "    ll = k_s[i]\n",
    "    dis = []\n",
    "    ind = []\n",
    "    for index in ll:\n",
    "        dis_index = dist(cent,reduced_data[index])\n",
    "        dis.append(dis_index)\n",
    "        ind.append(index)\n",
    "    dis_min = np.min(dis)\n",
    "    index_min = ll[dis.index(dis_min)]\n",
    "    #dis_max = np.max(dis)\n",
    "    #dis_mean = np.mean(dis)\n",
    "    print i,dis_min,index_min#,dis_max,dis_mean\n",
    "    #reduced_data[ll]\n",
    "    #print i,cent,len(ll),reduced_data[ll]\n",
    "\n",
    "cent = centroids[0]\n",
    "data = reduced_data[289]\n",
    "print dist(cent,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] <type 'list'>\n",
      "[1 2 3] <type 'numpy.ndarray'>\n",
      "1.73205080757\n",
      "197.291662267\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=[2,3,4]\n",
    "#dis=np.linalg.norm(a,b)\n",
    "#print dis\n",
    "aa = np.array(a)\n",
    "bb = np.array(b)\n",
    "print a,type(a)\n",
    "print aa,type(aa)\n",
    "\n",
    "def dis(x,y):\n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "dis = dis(aa,bb)\n",
    "print dis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.聚类结果输出到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"news540\")\n",
    "news = []\n",
    "\n",
    "for line in f:\n",
    "    news.append(line)\n",
    "\n",
    "f.close()\n",
    "\n",
    "g = open(\"clus_result/k_means_result_50tfidf_10clus\",\"w\")\n",
    "        \n",
    "for k in k_s:\n",
    "    k_l = k_s[k]\n",
    "    for ll in k_l:\n",
    "        g.write((\"%s||%s\\n\") % (news[ll], k))\n",
    "    \n",
    "    g.write((\"----End of the %d cluster---------------------------------------------\\n\") % k)\n",
    "    g.write((\"----------------------------------------------------------------------\\n\") % k)\n",
    "\n",
    "g.flush()\n",
    "g.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.附加：聚类效果比较：\n",
    "前提，labels必须是事先打好的类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "\n",
    "def k_means_model(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('% 9s   %.2fs    %i   %.3f   %.3f   %.3f   %.3f   %.3f    %.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means++   0.21s    22428   0.019   0.014   0.016   -0.001   -0.007    0.051\n",
      "   random   0.06s    22446   0.027   0.031   0.029   -0.022   0.000    0.036\n",
      "PCA-based   0.01s    24935   0.006   0.006   0.006   0.001   -0.006    0.034\n"
     ]
    }
   ],
   "source": [
    "k_means_model(KMeans(init='k-means++', n_clusters=n_clusters, n_init=n_init),\n",
    "              name=\"k-means++\", data=data)\n",
    "\n",
    "k_means_model(KMeans(init='random', n_clusters=n_clusters, n_init=n_init),\n",
    "              name=\"random\", data=data)\n",
    "\n",
    "pca = PCA(n_components=n_tags).fit(data.toarray())\n",
    "k_means_model(KMeans(init=pca.components_, n_clusters=n_clusters, n_init=n_init),\n",
    "              name=\"PCA-based\",\n",
    "              data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
